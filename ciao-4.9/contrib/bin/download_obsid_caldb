#! /usr/bin/env python

#
# Copyright (C) 2013-2017 Smithsonian Astrophysical Observatory
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
#

from __future__ import print_function

toolname = "download_obsid_caldb"
__revision__ = "28 March 2017"

import os
import sys

CDA_SERVER = "ftp://cdaftp.cfa.harvard.edu/pub/arcftp/ChandraCalDB"
CDA_ENV = "CALDB_MIRROR_SITE" 


import ciao_contrib.logger_wrapper as lw
lw.initialize_logger(toolname)
lgr = lw.get_logger(toolname)
verb0 = lgr.verbose0
verb1 = lgr.verbose1
verb2 = lgr.verbose2
verb3 = lgr.verbose3
verb5 = lgr.verbose5


import six


#
# Ripped off from Doug's download_chandra_obsid  stuff
#

# Wrapper around a file for writing to write a hash sign every x%
# of the file has been downloaded.
#
# This is based on code from the Tools/scripts/ftpmirror.py in the
# Python distribution.
#
class LoggingFile:

    hashchr = '#'

    def __init__(self, fp, filesize, outfp, startfrom=None, nhash=20):
        """nhash is the number of hashes to print (so 100/nhash is the
        percentage of the file content for each #)."""
        if nhash < 1:
            raise ValueError("nhash must be >= 1, sent {}".format(nhash))
        self.fp = fp
        if startfrom == None:
            self.bytes = 0
        else:
            if startfrom > filesize:
                raise ValueError("startfrom > filesize ({} vs {})".format(startfrom,filesize))
            self.bytes = startfrom - 1
        self.hashes = 0
        self.filesize = filesize
        self.nhash = nhash
        self.blocksize = filesize / self.nhash
        self.outfp = outfp

    def write(self, data):
        self.bytes = self.bytes + len(data)
        hashes = int(self.bytes) / self.blocksize
        if True:  # logger.getEffectiveVerbose() > 0:
            while hashes > self.hashes:
                self.outfp.write(self.hashchr)
                self.outfp.flush()
                self.hashes = self.hashes + 1
                
        self.fp.write(data)

    def close(self):
        # hack around rounding errors
        nh = self.nhash - self.hashes
        if True:  # logger.getEffectiveVerbose() > 0:
            if nh > 0 and self.bytes >= self.filesize:
                self.outfp.write('#' * nh)

            self.outfp.write("\n")
            self.outfp.flush()


class FtpFile():
    """
    Little wrapper class to get the file size
    """
    def __init__( self, ftp, path ):
        self.ftp = ftp
        self.path = path

    def get_ftp_filesize( self):

        self.filesize = None

        def parse_size( line ):
            toks = line.split()
            self.filesize = int(toks[4])

        self.ftp.retrlines("LIST " + self.path, parse_size)
        
        return( self.filesize )



def parse_url():
    """
    Allow user to override CALDB location via env variable similar to
    how download_chandra_obsid works.  Also ripped off from Doug's
    stuff.
    
    setenv CALDB_MIRROR_SITE "ftp://user:password@host:port/dir"

    Only FTP protocol is supported.
        
    """

    def get_id():
        """
        get a real user name if there is one.  
        """
        from socket import getfqdn
        u = "anonymous"
        for o in ["USER", "USERNAME"]:
            if o in os.environ:
                u=os.environ[o]

        mybox = getfqdn()
        if not mybox:
            mybox = toolname
        
        return "{}@{}".format(u, mybox)  


    try: 
        if CDA_ENV not in os.environ:
            url = six.moves.urllib.parse.urlparse( CDA_SERVER )
        else:
            url = six.moves.urllib.parse.urlparse( os.environ[CDA_ENV])
    except:
        raise ValueError("Bad {} setting".format(CDA_ENV))
        
    if url.scheme != "ftp":
        raise ValueError('The mirror site must begin with ftp://')

    host = url.hostname
    path = url.path
    user = "anonymous" if not url.username else url.username
    pswd = get_id() if not url.password else url.password

    verb2("Using FTP host='{}' dir='{}' user='{}' password='{}'".format( host, path, user, pswd))
    return host, path, user, pswd


def init_ftp():
    """
    Connect to ftp site
    """
    
    from ftplib import FTP

    host, path, user, pswd = parse_url()
    ftp = FTP(host, user=user, passwd=pswd)

    return ftp, path


def close_ftp(ftp):
    """
    May not be needed but do it nicely.
    """
    if ftp:
        ftp.close()


def retrieve_config_files(ftp, newver, rootdir, outdir):
    """
    Retrieve the instrument specific CALDB caldb.indx and key.config files.

    In classic mode, the caldb.indx and key.config files will be stored
    under data/chandra/{instrume}.  
    
    In the non-classic mode, the caldb.indx and key.config files
    will be stored in
    
    config/{instrume}-{version}.indx and .config
    
    which allows the user to change versions without having to manipulate
    symbolic links.

    """


    verb1( "Retrieving CALDB index files")

    ftp.cwd("/{}/software/tools".format(rootdir))
    ftp.retrbinary( "RETR caldb.config", open("{}/caldb.config".format(outdir),"wb").write)

    ftp.cwd("/{}/data/chandra/".format(rootdir))
    for dd in ftp.nlst():            
        if dd in [ 'ephin', 'sim', 'pcad', 'pimms' ]:  
            continue
        ftp.cwd("/{}/data/chandra/{}".format(rootdir,dd))

        #
        # We store both the chandra/$inst/caldb.indx file to make
        # old-school caldb happy, but then we also store versioned
        # copies of the index and key.config files in the config/ 
        # directory.
        #

        init_output_dir( "{}/data/chandra/{}".format(outdir,dd))
        out_indx = open("{}/data/chandra/{}/caldb.indx".format(outdir,dd),"wb")
        out_key = open("{}/data/chandra/{}/key.config".format(outdir,dd),"wb")
        verb2("Index name :"+out_indx.name)
        verb2("Key Config name :"+out_key.name)
        ftp.retrbinary( "RETR caldb.indx", out_indx.write)
        ftp.retrbinary( "RETR key.config", out_key.write)
        out_indx.close()
        out_key.close()

        # Okay -- this is a bit wasteful x-ferring the file twice.  Could
        # replace with a copy

        init_output_dir( "{}/config".format(outdir))
        out_indx = open("{}/config/{}-{}.indx".format(outdir,dd,newver),"wb")
        out_key = open("{}/config/{}-{}.config".format(outdir,dd,newver),"wb")
        verb2("Index name :"+out_indx.name)
        verb2("Key Config name :"+out_key.name)
        ftp.retrbinary( "RETR caldb.indx", out_indx.write)
        ftp.retrbinary( "RETR key.config", out_key.write)
        out_indx.close()
        out_key.close()


def filter_config(newver, outdir):
    """
    Rename/replace the generic CALDB config files with version specific
    files.
    
    The Chandra caldb uses a generic configuration files
    
        root/software/tools/caldb.config
    
    that points to each of the instrument specific index files and
    key config files:
    
        root/data/chandra/instrument/caldb.indx
        root/data/chandra/instrument/key.config
    
    Where these are symbolic links to "version" specific files.
    
        caldb.indx -> ./index/caldbN0400.indx
    
    This makes keeping track of versions, and if desired using multiple
    versions a real headache.
    
    Instead, this script will download the generic index and config
    files, and tweak them to be version specific.
    
        caldb.config -> CHANDRA-${version}.config
        caldb.indx -> INSTRUMENT-${version}.indx
        key.config -> INSTRUMENT-${version}.config

    This makes keeping old version of the CALDB a lot easier.    

    In classic mode the caldb.config file is copied to the 
    traditional software/tools/caldb.config location.   How boring is
    that.
    """

        
    with open("{}/caldb.config".format(outdir), "r") as fp:
        cfg = fp.readlines()
    os.unlink( "{}/caldb.config".format(outdir) )

    # Copy config file to standard/classic location
    init_output_dir("{}/software/tools".format(outdir))
    orig_config = "{}/software/tools/caldb.config".format(outdir)
    with open( orig_config, "w") as fp:
        fp.writelines( cfg )
    
    # Generic caldb.config is setup for all HEASARC mission, just get chandra.
    chandra = [x for x in cfg if x.startswith("CHANDRA")]

    # remove ephin, sim, pcad, pimms
    chandra = [x for x in chandra if x.split()[1] not in ['EPHIN', 'PCAD', 'SIM', 'PIMMS' ]]

    for ii,cc in enumerate(chandra):
        #
        # Rename files, replace values in the versioned config file to
        # use the versioned index file names.
        #
        inst = cc.split(" ")[3].split("/")[2]
        chandra[ii] = cc.replace("data/chandra/"+inst, "config/")
        chandra[ii] = chandra[ii].replace("caldb.indx","{}-{}.indx".format(inst,newver))
        chandra[ii] = chandra[ii].replace("key.config","{}-{}.config".format(inst,newver))

    outconfig = "{}/config/CHANDRA-{}.config".format(outdir,newver)
    with open(outconfig, "w") as fp:
        fp.writelines(chandra)

    return outconfig


def get_version_file(ftp, rootdir, outdir):
    """
    Read the Chandra caldb version file.  Get the old version if
    it exists then download the new file.
    
    """
    from pycrates import read_file

    verdir = "{}/docs/chandra/caldb_version/".format(outdir)
    init_output_dir(verdir)
    outfile = "{}/caldb_version.fits".format(verdir)

    try:
        tab = read_file( outfile )
        _oldver = tab.get_column("CALDB_VER").values[-1] #last row
        try:
            oldver = _oldver.decode("ascii")
        except:
            oldver = _oldver
    except: 
        oldver = None

    if ftp:
        ftp.cwd("/{}/docs/chandra/caldb_version/".format(rootdir))
        ftp.retrbinary( "RETR caldb_version.fits", open(outfile,"wb").write)
    elif os.path.exists( outfile ):
        pass
    else:
        raise RuntimeError("Error: cannot locate caldb version file")

    tab = read_file( outfile )
    _newver = tab.get_column("CALDB_VER").values[-1] #last row
    
    try:
        newver = _newver.decode("ascii")
    except:
        newver = _newver

    
    if oldver and oldver != newver:
        verb0( "Old CALDB version '{}', New version will be '{}'".format(oldver,newver))

    verb1( "Retrieving files for CALDB_VER = {}".format(newver))
    return newver



def init_output_dir(outdir):
    import errno as errno

    try:
        os.makedirs(outdir)
    except OSError as ee:
        if ee.errno != errno.EEXIST:
            raise


def retrieve_caldb_file( ftp, rootdir, looking_for, outdir, clobber, missing ):
    """
    Retrieve the CALDB data files
    """
    if looking_for == None or 0 == len(looking_for):
        return

    # strip off the extension numbers, we want the whole file
    # get unique set of file names
    uniq = set([x.split('[')[0] for x in looking_for])

    for products in uniq:
        # This is used to graft the CALDB directory path onto the
        # outdir path. The os.path.join() is used to get the
        # outdir path w/ the trailing "/" (but only if it's not
        # already there).
        hasdir = os.path.dirname( products )
        zz = hasdir.replace( os.path.join(outdir,""), "", 1 )
        hasnam = os.path.basename(products)

        outfile = "{}/{}".format(hasdir,hasnam)
        updated = os.path.exists( outfile )

        sys.stderr.write("    {:<40s}".format(hasnam))

        if missing:
            sys.stderr.write( "."*20)
            good = "online" if updated else "* MISSING *"
            sys.stderr.write( " {}".format(good))            
        elif updated and not clobber:
            sys.stderr.write( "."*20)
            sys.stderr.write( " (skipped)")
        else:
            #
            # Note to future self:  Since FITS files are stored in 2880
            # blocks, we can't rely on file size to indicate that
            # files have changed.  Only by looking at checksum/datasum
            # which means we need to redownload the file (or come
            # up with a way to stream part of the file until enough
            # is read to get the CHECKSUM/DATASUM (in all extensions!)
            # to know file is unchanged.
            #

            init_output_dir( hasdir )
            ftp.cwd("/{}/{}".format(rootdir,zz))

            outfp = open(outfile,"wb")
            fsize = FtpFile( ftp, hasnam ).get_ftp_filesize()
            logdl = LoggingFile( outfp, fsize, sys.stderr, None )

            ftp.retrbinary( "RETR {}".format(hasnam), logdl.write, 8*1024)
            outfp.close()

            if updated:
                sys.stderr.write( ' (updated)')

        sys.stderr.write("\n")
        

def retrieve_files_by_tool( ftp, rootdir, tool, infile, outdir, clobber, missing ):
    """
    Use the CALDB to query for each of the files to know which to
    retrieve. 
    """
    from caldb4 import Caldb

    for prod in tool:
        verb3("Looking up CAL_CNAM={}".format(prod) )

        # Ideally, this would only be done once (per-infile) but there
        # look to be some memory wackiness when the same Caldb object 
        # has the .product changed -- it doesn't reset/reinit cleanly.
        cc = Caldb( infile=infile )
        cc.product = prod
        if tool[prod]:
            for constraint in tool[prod]:
                verb3("Overrding value {}={}".format(constraint, tool[prod][constraint] ))
                setattr(cc, constraint, tool[prod][constraint] )

        products = cc.search
        retrieve_caldb_file( ftp, rootdir, products, outdir, clobber, missing )
        cc.close


def get_all_products():
    """
    Not in use.

    This is a different way to find the caldb products -- it looks for
    all the index files and gets the unique set of CAL_CNAM values.
    
    The problem with this is that the same single fits file can have 
    multiple extensions, and each extension may have a different
    CAL_CNAM (eg ACIS CTI file p2_resp files).  This then makes the retreival
    look more messy since the file will be 'skipped' even in a clean caldb tree.
    Guess we could filter out certain ones -- but not sure any more/less
    complicated then the get_by_tool method below
    """
    from pycrates import read_file
        
    cidx = os.environ["CALDBCONFIG"]
    cdir = os.environ["CALDB"]
    with open( cidx, "r+") as fp:
        lines = fp.readlines()
    
    chandra = [x for x in lines if x.startswith("CHANDRA")]
    ciao = [x for x in chandra if x.split()[1] not in  ['EPHIN', 'PCAD', 'SIM' ]]
    ciao = [x for x in ciao if 'pimms' not in x.lower()]
    ciao = [ x.replace(" CALDB ", " {} ".format(cdir)) for x in ciao]
    idxfiles = [ os.path.join( x.split()[2], os.path.join( x.split()[3],x.split()[4] )) for x in ciao ]

    retval = {}
    for idx in idxfiles:        
        # Quality of 5 is bad, not retrieved
        tab = read_file(idx+"[cal_qual=:4.9]")
        # get list of unique code-names
        _prods = list(set(tab.get_column("cal_cnam").values)) 
        try:
            prods = [x.decode("ascii") for x in _prods ]
        except:
            prods = _prods
 
        for p in prods:
            retval[p] = None
        
    return [retval]
        

def get_tools(infile):
    """
    Identify the CALDB data product codes by tool.
    
    This list is not complete.  Duplicates are not included or they
    would be retrieve twice.
    
    So while OSIP is needed by mkgarf and tg_resolve_events, it
    only should up in tg_resolve_events.  Same thing with badpixel
    and gain files.

    TODO:  HRC RMF, others?
    
    """

    acis_process_events = { 'grade' : None,        # 'gradefile'
                            'grdimg' : None,       # 'grade_image_file'
                            'det_gain' : None,     # 'gainfile'
                            'evtsplt' : None,      # 'threshfile'
                            'cti' : None,          # 'ctifile' 
                            't_gain' : None,      # 'tgainfile'
                            'subpix' :None         # 'subpixfile'
                            }
    pixlib =  { "geom" : None,                # 'instruments' : None,
                "aimpts" : None,              # 'aimpoints' : None,
                "tdet" : None,                # 'tdet' : None,
                "sky" : None,                 # 'sky' : None,
                "sgeom" : None                # 'shell' : None,
              }
    #acis_build_badpix = { 'badpix' : None }   # 'infile' 
    ardlib = { 'axeffa' :  None,        # 'effarea_file'
               'vignet' : None,         # 'vignet_file'
               'qe' : None,             # 'qe'
               'qeu' : None,            # 'qeu'
               'badpix' : { 'ccd_id' : "" },         # 'badpix'
               'contam' : None,          # 'acis_contam'
               'greff' : None,          # 'tg_eff'
               'lsfparm' : None,       # 'lsf'
               ### 'rmf_file' : None,  # ???
               ### 'gain_file' : None # ???
               }
    mkacisrmf = {'sc_matrix' : None, } #infile
    mkarf = { 'dead_area' :   None  } # 'dafile'  
    mkwarf = { 'fef_pha' : None } # + dead_area
    mkpsfmap = {'reef' : None }
    tg_create_mask = {'wpsf' : None  }  # input_pos_tab
    tg_resolve_events ={'osip' : None}
    tgextract2 = {'DISP_REG' : None }  # 'region_file'
    tgextract = {'TGMASK2' : None, } # 'inregion_file'
    hrc_process_events  =  {
            'GAPLOOKUP' : None,
            'DEGAP' : None,
            'T_GMAP' : None,
            'GMAP' : None,
            'ADC' : None,
            'FPTEST' : None,
            'TAPRINGTEST' : None,
            'EFTEST' : None,
            'SATTEST' : None,
            'AMP_SF_COR' : None,        
        }
    misc = {
        'GTI_LIM' : None,  # dmgti (mtl_build_gti)
        'MATRIX' : None,    # HRC RMF files    
        'lsfparm' : { 'grattype' : 'HEG' },
        'TGPIMASK2' : None
        }

    
    return [ pixlib , ardlib, acis_process_events, mkwarf, mkarf, mkpsfmap, mkacisrmf , tg_create_mask, tg_resolve_events, tgextract, tgextract2, hrc_process_events, misc]



def create_config_files( ftp, rootdir, outdir  ):
    """
    Setup the config and index files for the partial CALDB directory.
    """
    init_output_dir( outdir )
    
    newver = get_version_file(ftp, rootdir, outdir)
    retrieve_config_files(ftp, newver, rootdir, outdir)
    newconfig = filter_config(newver, outdir)
    oldver = setup_caldb_environment( outdir, newconfig )

    return oldver


def setup_caldb_environment( outdir, newconfig ):
    """
    Setup the new CALDB environment variables.
    """

    if "CALDB" in os.environ:
        oldcaldb = os.environ["CALDB"]
    else:
        oldcaldb = None
        
    os.environ["CALDB"]=outdir
    os.environ["CALDBCONFIG"] = "{}/software/tools/caldb.config".format(outdir) #newconfig    

    return oldcaldb


def get_background_files( ftp, rootdir, infile, outdir, clobber, background_files, missing):
    """
    """
    
    import stk as stk
    from pycrates import read_file
    tab = read_file(infile)

    inst = tab.get_key_value("INSTRUME")
    if 'ACIS' == inst:
        from ciao_contrib.runtool import acis_bkgrnd_lookup
        acis_bkgrnd_lookup.punlearn()
        try:
            acis_bkgrnd_lookup( infile )
            bkgfiles = stk.build( acis_bkgrnd_lookup.outfile )
            retrieve_caldb_file( ftp, rootdir, bkgfiles, outdir, clobber, missing )
        except Exception as e:
            #print e
            pass

    elif 'HRC' == inst:
        from ciao_contrib.runtool import hrc_bkgrnd_lookup
        hrc_bkgrnd_lookup.punlearn()
        try:
            hrc_bkgrnd_lookup(infile, "event")
            bkgfiles = stk.build( hrc_bkgrnd_lookup.outfile)
            retrieve_caldb_file( ftp, rootdir, bkgfiles, outdir, clobber, missing )                
        except:
            pass
        
        try:
            hrc_bkgrnd_lookup(infile, "spectrum")
            bkgfiles = stk.build( hrc_bkgrnd_lookup.outfile)
            retrieve_caldb_file( ftp, rootdir, bkgfiles, outdir, clobber, missing )                
        except Exception as e:
            # print e
            pass            
    else:
        # Should have failed much sooner than now!
        raise RuntimeError("Unknown instrument")



def get_caldb_files( ftp, rootdir, infile, outdir, clobber, background_files, missing):
    """
    Get all possible CALDB files needed for this observation.
    
    """

    verb1( "Retrieving CALDB data files")
    sys.stderr.write("    {:<40s}0------------------1\n".format('Filename:'))

    for tool in get_tools(infile):
        retrieve_files_by_tool( ftp, rootdir, tool, infile, outdir, clobber, missing )

    if background_files:
        get_background_files( ftp, rootdir, infile, outdir, clobber, background_files, missing)


def print_new_setup(oldcaldb):
    """
    Let user know if new partial CALDB is different from their CALDB
    setup.
    """

    if (oldcaldb and os.path.abspath(oldcaldb) != os.path.abspath(os.environ["CALDB"])) or ( not oldcaldb):
        verb0( "\nBe sure to setup the following environment variables to")
        verb0( "use these CALDB files.")
        verb0( "")
        verb0( "(t)csh:")
        verb0( "setenv CALDB "+os.path.abspath(os.environ["CALDB"]))
        verb0( "setenv CALDBCONFIG "+os.path.abspath(os.environ["CALDBCONFIG"]))
        verb0( "")
        verb0( "bash:")
        verb0( "export CALDB="+os.path.abspath(os.environ["CALDB"]))
        verb0( "export CALDBCONFIG="+os.path.abspath(os.environ["CALDBCONFIG"]))
        verb0( "")


def locate_infile(infile):
    """
    Try to locate an event file if given a directory name
    """

    import glob as glob

    if os.path.isfile(infile):
        return infile
    
    if os.path.isfile(infile+".gz"):
        return infile+".gz"
    
    if os.path.isdir(infile):
        
        for dd in [ infile, infile+"/repro", infile+"/primary", infile+"/secondary" ]:
            gg = glob.glob( dd+"/*evt*" )
            if len(gg) == 0:
                continue
            if len(gg) > 1 :
                verb1("Multiple event file found, using {}".format(gg[0]))
                return gg[0]
            verb2("Using event file {}".format(gg[0]))
            return gg[0]
    
    raise IOError("Cannot locate event file in '{}'".format(infile))

    
def setup_check_missing( outdir ):
    """
    setup CALDB environment variable for new output dir
    """
    if not os.path.exists( outdir ):
        raise ValueError("ERROR: The output directory must already exist in missing mode.")
    
    if not os.path.exists( outdir+"/software/tools/caldb.config"):
        raise ValueError("ERROR: The CALDB configuration file must already exist in missing mode.")
        
    os.environ["CALDB"] = os.path.abspath(outdir)
    os.environ["CALDBCONFIG"] = os.environ["CALDB"]+"/software/tools/caldb.config"
    return os.environ["CALDB"]


#
# Main Routine
#
@lw.handle_ciao_errors( toolname, __revision__)
def main():
    # get parameters
    from ciao_contrib.param_soaker import get_params

    # Load parameters
    pars = get_params(toolname, "rw", sys.argv, 
        verbose={"set":lw.set_verbosity, "cmd":verb1} )

    infiles= pars["infile"]   
    outdir = pars["outdir"]   
    missing = ( "yes" == pars["missing"] )
    background_files = ("yes" == pars["background"] ) 
    clobber = ("yes" == pars["clobber"]) 
        

    if missing:
        ftp = None
        rootdir = None
        oldcaldb = setup_check_missing( outdir )    
        get_version_file( ftp, rootdir, outdir )
    else:
        ftp, rootdir = init_ftp()
        oldcaldb = create_config_files( ftp, rootdir, outdir )


    import stk as stk    
    for infile in stk.build( infiles ):
        try:
            infile = locate_infile( infile )
            verb1("Processing infile={}".format(infile))
        except:
            verb0("WARNING: Unable to locate evt2 file in '{}'.  Skipping it.".format(infile))
            continue
            
        get_caldb_files(ftp, rootdir, infile, outdir, clobber, background_files, missing)

    close_ftp(ftp)
    print_new_setup( oldcaldb )



if __name__ == "__main__":
    try:
        main()
    except Exception as E:
        print("\n# "+toolname+" ("+__revision__+"): ERROR "+str(E)+"\n", file=sys.stderr)
        sys.exit(1)
    sys.exit(0)
  
