<?xml version="1.0"?>
<!DOCTYPE cxchelptopics SYSTEM "CXCHelp.dtd">
<cxchelptopics>
  <ENTRY key="patch_hrc_ssc" context="Tools::HRC"
         refkeywords="hrc dtf deadtime dead time factor stat stats statistic statistics secondary science ssc corruption"
         seealsogroups="hrctools">

    <SYNOPSIS>
      Identify and patch HRC Secondary Science Corruption (SSC) data
    </SYNOPSIS>

    <DESC>
       <PARA>
  SSC results from a byte-shift anomaly which occasionally causes a
  portion of the housekeeping data to be corrupted.  The symptom is
  dropouts in the dead-time-factor (dtf) which can be seen in a plot
  of the dtf1 file's dtf valuse vs time, where the dtf is
  significantly (&gt;10%) below the median value (~1.0).
    </PARA>
       <PARA>

  In the dtf1 file are several rate columns.  The one that seems to
  reliably flag SSC is the TOTAL_EVT_COUNT, when it is anomalously
  high, with values &gt; 4000 (2000 count/s; the default binning is 2s,
  the dtf file values are integrated over time bins)
    </PARA>
       <PARA>

  Event data are good during the SSC times.  Standard data
  processing, however, will create multiple GTI intervals around the
  low dtf times, rejecting some events, and lowering the
  dead-time-correction factor (DTDOR).
    </PARA>
       <PARA>

  Note: telemetry saturation from a bright source can also cause
  lower dtf values.  That tends to be a more continuous and sustained
  lowering of the value.  Hence, inspection of the dtf and
  total_evt_count vs time is recommended.
       </PARA>

      <PARA title="Technical References:">
        <HREF link="https://cxc.harvard.edu/proposer/POG/html/chap7.html#tth_sEc7.12">
        Chandra Proposers and Observatory Guide secion on HRC SSC
        </HREF>          
      </PARA>
      <PARA><HREF link="https://cxc.harvard.edu/contrib/juda/memos/anomaly/sec_sci/index.html">
      HRC Secondary Science Anomaly on Day 2005:349</HREF></PARA>
      <PARA><HREF link="https://cxc.harvard.edu/contrib/juda/memos/anomaly/sec_sci/byte_shift.html">
        Secondary Science Byte Shift
      </HREF></PARA>
      <PARA><HREF link="https://sot.github.io/cheta/pseudo_msids.html">
      Pseudo-MSIDs in the engineering archive
      </HREF></PARA>
    </DESC>

    <QEXAMPLELIST>
       <QEXAMPLE>
         <SYNTAX>
           <LINE>patch_hrc_ssc dtf_in=primary/hrcf27499_000N001_dtf1.fits \</LINE>
           <LINE>  mtl_infile=secondary/hrcf27499_000N001_mtl1.fits \</LINE>
           <LINE>  evt_infile= secondary/hrcf27499_000N001_evt1.fits \</LINE>
           <LINE>  evt_outfile=patched_evt1.fits \</LINE>
           <LINE>  dtf_outfile=patched_dtf1.fits \</LINE>
           <LINE>  gti_outfile=patched_flt1.fits clob+ mode=h</LINE>
         </SYNTAX>
         <DESC>
<VERBATIM>
patch_hrc_ssc (10 October 2024)
      dtf_infile = primary/hrcf27499_000N001_dtf1.fits
      mtl_infile = secondary/hrcf27499_000N001_mtl1.fits
      evt_infile = secondary/hrcf27499_000N001_evt1.fits
     evt_outfile = patched_evt1.fits
     gti_outfile = patched_flt1.fits
     dtf_outfile = patched_dtf1.fits
       threshold = 4000
    smooth_count = 3
          tmpdir = /tmp
         verbose = 1
         clobber = yes
            mode = h

SSC detected; patching
DTF_MEDIAN = 0.99117975 (0.0007477008299119561)
Patching DTF values in primary/hrcf27499_000N001_dtf1.fits
Patching DTF values in /tmp/tmprtqf975j_mtl.fits
Creating new GTI limits
Make new flt file...
Recomputing DTF stats
New DTCOR=0.9912249218272523
Updating DTCOR in event file and recomputing EXPOSURE time
</VERBATIM>
           <PARA>
                In this example, OBS_ID 27499 experiences secondary
                science corruption which is detected and patched by
                the script. The output files are a new
                dead time factors file (dtf1.fits), a new
                level 1 event file (evt1.fits), and a new
                good time intervals, aka filter file, (flt1.fits). 
           </PARA>         
           <PARA>
                The script must be run with the level 1 event file since
                the level 2 event file already has data outside the bad intervals removed.                
           </PARA>

         </DESC>
       </QEXAMPLE>

       <QEXAMPLE>
         <SYNTAX>
           <LINE>patch_hrc_ssc dtf_in= primary/hrcf01297_000N004_dtf1.fits \</LINE>
           <LINE>evt_in=secondary/hrcf01297_000N004_evt1.fits \</LINE>
           <LINE>mtl_in=secondary/hrcf01297_000N004_mtl1.fits \</LINE>
           <LINE>dtf_out=patched_dtf1.fits evt_out=patched_evt1.fits gti_out=patch_flt1.fits \</LINE>
           <LINE>mode=h clob+</LINE>
         </SYNTAX>
         <DESC>
<VERBATIM>
patch_hrc_ssc (10 October 2024)
      dtf_infile = primary/hrcf01297_000N004_dtf1.fits
      mtl_infile = secondary/hrcf01297_000N004_mtl1.fits
      evt_infile = secondary/hrcf01297_000N004_evt1.fits
     evt_outfile = patched_evt1.fits
     gti_outfile = patch_flt1.fits
     dtf_outfile = patched_dtf1.fits
       threshold = 4000
    smooth_count = 3
          tmpdir = /tmp
         verbose = 1
         clobber = yes
            mode = h

SSC not detected, no action required.
</VERBATIM>
           <PARA>
            In this example with OBS_ID 1297, there is no secondary science
            corruption detected. In this case there are no output files
            create and the exit status of the tool is 0 (ie good).
           </PARA>         
         </DESC>
       </QEXAMPLE>

    </QEXAMPLELIST>

    <PARAMLIST>
     <PARAM name="dtf_infile" type="file" filetype="input" reqd="yes">
       <SYNOPSIS>
            The input Level 1 dead time factors file, dtf1.fits.
       </SYNOPSIS>
     </PARAM>
     <PARAM name="mtl_infile" type="file" filetype="input" reqd="yes">
       <SYNOPSIS>
          The input Level 1 mission time line file, mtl1.fits.
       </SYNOPSIS>
     </PARAM>
     <PARAM name="evt_infile" type="file" filetype="input" reqd="yes">
       <SYNOPSIS>
         The input Level 1 event file, evt1.fits. 
       </SYNOPSIS>
       <DESC>
         <PARA>
            Users should use the Level 1 event file because you cannot
            recover the updated Good Time Intervals from the already filtered
            Level 2 event file.  
         </PARA>
       </DESC>     
     </PARAM>
     <PARAM name="evt_outfile" type="file" filetype="output" reqd="yes">
       <SYNOPSIS>
          The output Level 1 event file.
       </SYNOPSIS>
       <DESC>
         <PARA>
            The output level 1 event file is a copy of the input 
            level 1 event file with the following keywords modified:
         </PARA>
          <LIST>
            <ITEM>DTCOR : This value is updated based on the patched dead time
            factor values.</ITEM>
            <ITEM>DTFFILE : This keyword is updated to be the dtf_outfile file name.</ITEM>
            <ITEM>FLTFILE : This keyword is updated to be the gti_outfile file name.</ITEM>          
            <ITEM>SSC = True : This keyword indicates that the secondary science
            corruption was detected.</ITEM>
            <ITEM>SSCFIX = True: This keyword indicates that the secondary science
            correction was fixed (patched).</ITEM>
          </LIST>

          <PARA>This file should be used in place of the standard archived
          Level 1 event file in processing.</PARA>

       </DESC>     
     </PARAM>
     <PARAM name="gti_outfile" type="file" filetype="output" reqd="yes">
       <SYNOPSIS>
          The output good time intervals, aka filter, file.
       </SYNOPSIS>
       <DESC>
         <PARA>
             The good time intervals are recomputed from the mission time
             line file based on the patched DTF values and removing the 
             limit on the IMHVLV and IMHBLV values. 
         </PARA>
       </DESC>     
     </PARAM>
     <PARAM name="dtf_outfile" type="file" filetype="output" reqd="yes">
       <SYNOPSIS>
            The output dead time factors file.
       </SYNOPSIS>
       <DESC>
         <PARA>
            The median DTF and DTF_ERR values outside the secondary science 
            correction time are used to replace the values in the dtf_infile.            
         </PARA>
       </DESC>     
     </PARAM>
     <PARAM name="threshold" type="integer" def="4000" reqd="yes">
       <SYNOPSIS>
        The TOTAL_EVT_COUNT threshold used to identify SSC.
       </SYNOPSIS>
     </PARAM>
     <PARAM name="smooth_count" type="integer" def="3" >
       <SYNOPSIS>
          Smoothing applied to the TOTAL_EVT_COUNT column 
       </SYNOPSIS>
       <DESC>
         <PARA>
            The TOTAL_EVT_COUNT column is smoothed over this many rows
            when looking for values above the threshold parameter.
         </PARA>
       </DESC>     
     </PARAM>
     <PARAM name="tmpdir" filetype="output" type="file" reqd="no" def="${ASCDS_WORK_PATH}">
        <SYNOPSIS>Temporary working directory</SYNOPSIS>
        <DESC>
          <PARA>
                Directory used to store temporary file created by the script.
          </PARA>
        </DESC>
      </PARAM>
     <PARAM name="verbose" type="integer" min="0" max="5" def="1">
       <SYNOPSIS>
        Amount of tool chatter level.
       </SYNOPSIS>
     </PARAM>

      <PARAM name="clobber" type="boolean" def="no">
        <SYNOPSIS>
            Overwrite output files if they already exist?
        </SYNOPSIS>
      </PARAM>

   
   </PARAMLIST>

 
    <ADESC title="About Contributed Software">
      <PARA>
        This script is not an official part of the CIAO release but is
        made available as "contributed" software via the
        <HREF link="https://cxc.harvard.edu/ciao/download/scripts/">CIAO scripts page</HREF>.
        Please see this page for installation instructions.
      </PARA>
    </ADESC>
    

    <BUGS>
      <PARA>
        See the
        <HREF link="https://cxc.harvard.edu/ciao/bugs/patch_hrc_ssc.html">bug
        pages</HREF>
        on the CIAO website for an up-to-date listing of known bugs.
      </PARA>
    </BUGS>
    
    <LASTMODIFIED>December 2024</LASTMODIFIED>

  </ENTRY>    
</cxchelptopics>
